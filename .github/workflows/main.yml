name: JMeter Test Workflow

on:
  push:
    branches: [ main, master ]
  workflow_dispatch:  # Allow manual triggering

jobs:
  jmeter-tests:
    runs-on: ubuntu-latest

    steps:
      # ✅ Checkout the repository
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # This ensures we get the full history for commits

      # ✅ Install JMeter
      - name: Install JMeter
        run: |
          sudo apt update
          sudo apt install -y openjdk-11-jre
          wget https://archive.apache.org/dist/jmeter/binaries/apache-jmeter-5.6.2.tgz
          tar -xvzf apache-jmeter-5.6.2.tgz
          echo "JMETER_HOME=$(pwd)/apache-jmeter-5.6.2" >> $GITHUB_ENV
          echo "$(pwd)/apache-jmeter-5.6.2/bin" >> $GITHUB_PATH

      # ✅ Install dependencies for history update
      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y jq  # Install jq for JSON processing

      # ✅ Reload environment variables
      - name: Load environment variables
        run: source $GITHUB_ENV

      # ✅ Verify JMeter installation
      - name: Verify JMeter Installation
        run: |
          jmeter --version

      # ✅ Setup Node.js for deletion API
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'

      # ✅ Install Node.js dependencies if package.json exists
      - name: Install Node.js dependencies
        run: |
          if [ -f "scripts/package.json" ]; then
            cd scripts
            npm install
          elif [ -f "package.json" ]; then
            npm install
          else
            echo "No package.json found, skipping npm install"
          fi

      # ✅ Create report directories
      - name: Create report directories
        run: |
          mkdir -p ./jmeter-pages/reports
          mkdir -p ./jmeter-tests/results
          mkdir -p ./jmeter-pages/history
          mkdir -p ./jmeter-pages/comparison
          chmod -R 755 ./jmeter-pages
          mkdir -p ./reports/$(date +"%Y-%m-%d_%H-%M-%S")

      # ✅ Initialize history file if not exists
      - name: Initialize history files
        run: |
          mkdir -p scripts/history
          mkdir -p reports/history
          
          # Create empty history file if not exists
          if [ ! -f "scripts/history/history.json" ]; then
            echo '{"tests":[]}' > scripts/history/history.json
          fi
          
          # Copy to other locations
          cp scripts/history/history.json reports/history/history.json || true
          
          # Create jmeter-pages/history/history.json
          mkdir -p ./jmeter-pages/history
          cp scripts/history/history.json ./jmeter-pages/history/history.json || true

      # ✅ Handle JMeter Tests
      - name: Run or Skip JMeter Tests
        run: |
          if [ -f "./C_1.jmx" ]; then
            # Run JMeter test if JMX file exists
            echo "Found C_1.jmx file. Running JMeter test with real data..."
            jmeter -n \
              -t ./C_1.jmx \
              -l ./jmeter-tests/results/results.jtl \
              -e -o ./jmeter-pages/reports \
              -Jthreads=100 -Jrampup=10 -Jduration=60 -f
            
            # Display test summary right after execution
            echo "JMeter Test Execution Summary:"
            cat ./jmeter-pages/reports/statistics.json | jq '.' || echo "No statistics found"
          else
            echo "No C_1.jmx file found. Creating sample results for demonstration."
            mkdir -p ./jmeter-tests/results
            
            # Create a sample JTL file
            echo "timeStamp,elapsed,label,responseCode,responseMessage,threadName,success,bytes,sentBytes,grpThreads,allThreads,Latency,IdleTime,Connect" > ./jmeter-tests/results/results.jtl
            echo "$(date +%s%3N),200,Sample Request,200,OK,Thread Group 1-1,true,1000,500,1,1,100,0,50" >> ./jmeter-tests/results/results.jtl
            
            # Create a sample report directory structure
            mkdir -p ./jmeter-pages/reports/statistics
            echo "<html><body><h1>Sample JMeter Report</h1></body></html>" > ./jmeter-pages/reports/index.html
            echo '{"Total":{"sampleCount":1,"errorCount":0,"errorPct":0,"meanResTime":200}}' > ./jmeter-pages/reports/statistics/statistics.json
          fi
          
          # Copy results to reports directory for history tracking
          TIMESTAMP=$(date +"%Y-%m-%d_%H-%M-%S")
          mkdir -p ./reports/$TIMESTAMP/JMeterTest
          
          # Copy the JTL file if it exists
          if [ -f "./jmeter-tests/results/results.jtl" ]; then
            cp ./jmeter-tests/results/results.jtl ./reports/$TIMESTAMP/
          fi
          
          # Copy reports statistics to history directory if they exist
          if [ -f "./jmeter-pages/reports/statistics.json" ]; then
            cp ./jmeter-pages/reports/statistics.json ./reports/$TIMESTAMP/JMeterTest/ || true
          fi
          
          # Create statistics.json file if it doesn't exist already
          if [ ! -f "./reports/$TIMESTAMP/JMeterTest/statistics.json" ]; then
            echo "{" > ./reports/$TIMESTAMP/JMeterTest/statistics.json
            echo "  \"Total\": {" >> ./reports/$TIMESTAMP/JMeterTest/statistics.json
            echo "    \"transaction\": \"Total\"," >> ./reports/$TIMESTAMP/JMeterTest/statistics.json
            
            if [ -f "./jmeter-tests/results/results.jtl" ]; then
              # Use real data if available
              SAMPLE_COUNT=$(grep -c "" ./jmeter-tests/results/results.jtl || echo "1")
              ERROR_COUNT=$(grep -c ",false," ./jmeter-tests/results/results.jtl || echo "0")
              
              # Handle division by zero
              if [ "$SAMPLE_COUNT" -eq "0" ]; then
                ERROR_PCT=0
              else
                ERROR_PCT=$(awk "BEGIN {print ($ERROR_COUNT/$SAMPLE_COUNT)*100}")
              fi
              
              MEAN_TIME=$(awk -F "," '{sum+=$2} END {print sum/NR}' ./jmeter-tests/results/results.jtl || echo "200")
            else
              # Use sample data if no JTL file
              SAMPLE_COUNT=1
              ERROR_COUNT=0
              ERROR_PCT=0
              MEAN_TIME=200
            fi
            
            echo "    \"sampleCount\": $SAMPLE_COUNT," >> ./reports/$TIMESTAMP/JMeterTest/statistics.json
            echo "    \"errorCount\": $ERROR_COUNT," >> ./reports/$TIMESTAMP/JMeterTest/statistics.json
            echo "    \"errorPct\": $ERROR_PCT," >> ./reports/$TIMESTAMP/JMeterTest/statistics.json
            echo "    \"meanResTime\": $MEAN_TIME" >> ./reports/$TIMESTAMP/JMeterTest/statistics.json
            echo "  }" >> ./reports/$TIMESTAMP/JMeterTest/statistics.json
            echo "}" >> ./reports/$TIMESTAMP/JMeterTest/statistics.json
          fi

      # ✅ Make scripts executable
      - name: Make scripts executable
        run: |
          find scripts -name "*.sh" -exec chmod +x {} \; || true

      # ✅ Update history file
      - name: Update history file
        run: |
          if [ -f "./scripts/update_history.sh" ]; then
            chmod +x ./scripts/update_history.sh
            ./scripts/update_history.sh
          else
            echo "Warning: update_history.sh script not found, using built-in history update"
            
            # Create sample history entry
            TIMESTAMP=$(date +"%Y-%m-%d_%H-%M-%S")
            HISTORY_FILE="scripts/history/history.json"
            
            # Extract success rate and response time from statistics file
            echo "Extracting metrics from statistics file at ./reports/$TIMESTAMP/JMeterTest/statistics.json"
            
            if [ -f "./reports/$TIMESTAMP/JMeterTest/statistics.json" ]; then
              cat ./reports/$TIMESTAMP/JMeterTest/statistics.json
              
              ERROR_PCT=$(jq -r '.Total.errorPct' ./reports/$TIMESTAMP/JMeterTest/statistics.json)
              SUCCESS_RATE=$(echo "100 - $ERROR_PCT" | bc)
              AVG_RESPONSE_TIME=$(jq -r '.Total.meanResTime' ./reports/$TIMESTAMP/JMeterTest/statistics.json)
              
              echo "Extracted metrics: Success Rate=$SUCCESS_RATE%, Avg Response Time=$AVG_RESPONSE_TIME ms"
              
              # Validate response time (avoid unrealistic values) - use 100,000 ms (100 seconds) as threshold
              if [ $(echo "$AVG_RESPONSE_TIME < 100000" | bc -l) -eq 1 ]; then
                # Check if this timestamp already exists in the history file
                if [ -f "$HISTORY_FILE" ]; then
                  TIMESTAMP_EXISTS=$(jq --arg ts "$TIMESTAMP" '.tests | map(select(.timestamp == $ts)) | length' "$HISTORY_FILE")
                else
                  TIMESTAMP_EXISTS=0
                  echo '{"tests":[]}' > "$HISTORY_FILE"
                fi
                
                if [ "$TIMESTAMP_EXISTS" -eq "0" ]; then
                  # Add to history file using temp file approach
                  jq --arg timestamp "$TIMESTAMP" \
                     --arg test "JMeterTest" \
                     --argjson success_rate "$SUCCESS_RATE" \
                     --argjson avg_response "$AVG_RESPONSE_TIME" \
                     --arg report_path "reports/$TIMESTAMP" \
                     '.tests += [{"timestamp": $timestamp, "test": $test, "success_rate": $success_rate, "avg_response_time": $avg_response, "report_path": $report_path}]' \
                     "$HISTORY_FILE" > "${HISTORY_FILE}.tmp" && mv "${HISTORY_FILE}.tmp" "$HISTORY_FILE"
                  
                  # Sort tests by timestamp (newest first)
                  jq '.tests = (.tests | sort_by(.timestamp) | reverse)' "$HISTORY_FILE" > "${HISTORY_FILE}.tmp" && mv "${HISTORY_FILE}.tmp" "$HISTORY_FILE"
                     
                  echo "Added test results to history file"
                else
                  echo "Timestamp $TIMESTAMP already exists in history file. Skipping."
                fi
              else
                echo "Warning: Unrealistic response time ($AVG_RESPONSE_TIME ms) detected. Skipping history update."
              fi
              
              # Display updated history file
              echo "Updated history file:"
              cat "$HISTORY_FILE" | jq '.'
            else
              echo "Warning: Statistics file not found at ./reports/$TIMESTAMP/JMeterTest/statistics.json"
            fi
          fi

      # ✅ Copy history files to key locations
      - name: Copy history files to key locations
        run: |
          mkdir -p reports/history
          mkdir -p scripts/history
          mkdir -p history
          mkdir -p ./jmeter-pages/history
          
          # Copy files if they exist
          [ -f "scripts/history/history.json" ] && cp scripts/history/history.json reports/history/history.json || true
          [ -f "scripts/history/history.json" ] && cp scripts/history/history.json history/history.json || true
          [ -f "scripts/history/history.json" ] && cp scripts/history/history.json ./jmeter-pages/history/history.json || true

      # ✅ Copy comparison files
      - name: Copy comparison files
        run: |
          # Copy comparison viewer files if they exist
          if [ -f "scripts/comparison_viewer.html" ]; then
            mkdir -p ./jmeter-pages/comparison
            cp scripts/comparison_viewer.html ./jmeter-pages/comparison/index.html || true
            cp scripts/comparison_viewer.js ./jmeter-pages/comparison/ || true
          fi
          
          # Create a simple comparison page if the files don't exist
          if [ ! -f "./jmeter-pages/comparison/index.html" ]; then
            mkdir -p ./jmeter-pages/comparison
            # Create simple page with echo instead of heredoc
            echo '<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>JMeter Test Comparison</title><link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet"></head><body><div class="container mt-5"><h1>JMeter Test Comparison</h1><p>This page allows you to compare JMeter test results.</p><p>View the <a href="../history/">history dashboard</a> or <a href="../reports/">test reports</a>.</p></div></body></html>' > ./jmeter-pages/comparison/index.html
          fi

      # ✅ Run comparison setup (if script exists)
      - name: Set up Comparison Tool
        run: |
          if [ -f "./scripts/run_comparison.sh" ]; then
            chmod +x ./scripts/run_comparison.sh
            ./scripts/run_comparison.sh ./jmeter-tests/results/results.jtl || true
          else
            echo "No run_comparison.sh script found, skipping comparison setup."
          fi

      # ✅ Display Test Summary
      - name: Display Test Summary
        run: |
          echo "Test Summary:"
          if [ -f "./jmeter-tests/results/results.jtl" ]; then
            grep "summary =" ./jmeter-tests/results/results.jtl || echo "No summary found in JTL file"
          else
            echo "No JTL file found"
          fi

      # ✅ Copy history dashboard to public directory
      - name: Create history dashboard
        run: |
          mkdir -p ./jmeter-pages/history
          
          if [ -f "reports/history/index.html" ]; then
            cp reports/history/index.html ./jmeter-pages/history/
          else
            # Create simple dashboard with echo instead of heredoc
            echo '<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>JMeter Test History</title><link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet"></head><body><div class="container mt-5"><h1>JMeter Test History</h1><p>This page shows the history of JMeter test executions.</p><p>View the <a href="../comparison/">comparison dashboard</a> or <a href="../reports/">test reports</a>.</p><div class="mt-4"><h2>Test Results</h2><div id="results">Loading...</div></div></div><script>async function loadResults() {try {const response = await fetch("history.json");const data = await response.json();if (data.tests && data.tests.length > 0) {const resultsDiv = document.getElementById("results");resultsDiv.innerHTML = "<table class=\"table table-striped\"><thead><tr><th>Date</th><th>Test</th><th>Success Rate</th><th>Response Time</th></tr></thead><tbody></tbody></table>";const tbody = resultsDiv.querySelector("tbody");data.tests.forEach(test => {const row = document.createElement("tr");row.innerHTML = `<td>${test.timestamp.replace(/_/g, " ")}</td><td>${test.test}</td><td>${test.success_rate.toFixed(2)}%</td><td>${test.avg_response_time.toFixed(2)} ms</td>`;tbody.appendChild(row);});} else {document.getElementById("results").innerHTML = "<div class=\"alert alert-info\">No test results found.</div>";}} catch (error) {document.getElementById("results").innerHTML = `<div class="alert alert-danger">Error loading test results: ${error.message}</div>`;}}document.addEventListener("DOMContentLoaded", loadResults);</script></body></html>' > ./jmeter-pages/history/index.html
          fi

      # ✅ Create artifacts for deployment
      - name: Prepare artifacts
        run: |
          # Create a package for all deployable files
          mkdir -p ./deployment-package
          
          # Copy reports
          if [ -d "./jmeter-pages/reports" ]; then
            mkdir -p ./deployment-package/reports
            cp -r ./jmeter-pages/reports/* ./deployment-package/reports/ || true
          fi
          
          # Copy history
          if [ -d "./jmeter-pages/history" ]; then
            mkdir -p ./deployment-package/history
            cp -r ./jmeter-pages/history/* ./deployment-package/history/ || true
          fi
          
          # Copy comparison
          if [ -d "./jmeter-pages/comparison" ]; then
            mkdir -p ./deployment-package/comparison
            cp -r ./jmeter-pages/comparison/* ./deployment-package/comparison/ || true
          fi
          
          # Create main index.html file with echo instead of heredoc
          echo '<!DOCTYPE html><html><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>JMeter Test Dashboard</title><link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet"></head><body><div class="container mt-5"><h1>JMeter Test Dashboard</h1><div class="row mt-4"><div class="col-md-4"><div class="card"><div class="card-body"><h5 class="card-title">Test Reports</h5><p class="card-text">View detailed reports for the latest JMeter test run.</p><a href="reports/" class="btn btn-primary">View Reports</a></div></div></div><div class="col-md-4"><div class="card"><div class="card-body"><h5 class="card-title">Test History</h5><p class="card-text">View historical data from all test executions.</p><a href="history/" class="btn btn-primary">View History</a></div></div></div><div class="col-md-4"><div class="card"><div class="card-body"><h5 class="card-title">Test Comparison</h5><p class="card-text">Compare results between different test runs.</p><a href="comparison/" class="btn btn-primary">Compare Tests</a></div></div></div></div></div></body></html>' > ./deployment-package/index.html

      # ✅ Upload main deployment package
      - name: Upload Deployment Package
        uses: actions/upload-artifact@v4
        with:
          name: deployment-package
          path: ./deployment-package
          retention-days: 30  # Keep artifacts for 30 days

      # ✅ Commit and push changes
      - name: Commit and push changes
        uses: EndBug/add-and-commit@v9
        with:
          add: 'history/*.json reports/history/*.json scripts/history/*.json reports/'
          message: 'Update test history [skip ci]'
          default_author: github_actions

  # ✅ GitHub Pages Deployment
  deploy:
    needs: jmeter-tests
    runs-on: ubuntu-latest

    steps:
      # ✅ Checkout repository
      - name: Checkout repository
        uses: actions/checkout@v4

      # ✅ Download Deployment Package
      - name: Download Deployment Package
        uses: actions/download-artifact@v4
        with:
          name: deployment-package
          path: ./public

      # ✅ Deploy to GitHub Pages
      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./public
          publish_branch: gh-pages
          user_name: 'github-actions[bot]'
          user_email: 'github-actions[bot]@users.noreply.github.com'
          full_commit_message: 'Deploy JMeter test reports from ${{ github.sha }}' 
